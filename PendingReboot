Exit code 0: Up
Exit code 1: Warning
Exit code 2: Critical
Exit code 3: Unknown

#simple
Get-ItemProperty -Path 'HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootPending' -ErrorAction SilentlyContinue | Select-Object -Property *


# Minimal Reboot Pending Detection Script with Exit Codes

# Define Registry Keys to Check
$RebootRegKeys = @(
    "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootPending",
    "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\WindowsUpdate\Auto Update\RebootRequired",
    "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootInProgress",
    "HKLM:\SYSTEM\CurrentControlSet\Control\Session Manager\PendingFileRenameOperations"
)

# Check for Pending Reboot
$PendingReboot = (
    ($RebootRegKeys | Where-Object { Test-Path $_ }) -or 
    (New-Object -ComObject Microsoft.Update.SystemInfo).RebootRequired
)

# Output Results in SolarWinds-Compatible Format
if ($PendingReboot) {
    Write-Host "Message.RebootStatus: Server is pending reboot"
    Write-Host "Statistic.RebootStatus: 1"
    exit 2 # Exit with Warning (2) status
} else {
    Write-Host "Message.RebootStatus: Server is not pending reboot"
    Write-Host "Statistic.RebootStatus: 0"
    exit 0 # Exit with Up (0) status
}




# Streamlined Script to Check Pending Reboot

# Define Registry Keys to Check
$RebootRegKey1 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootPending"
$RebootRegKey2 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\WindowsUpdate\Auto Update\RebootRequired"
$RebootRegKey3 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootInProgress"

# Initialize Pending Reboot Flag
$PendingReboot = $false

# Check Registry Keys Individually and Combine Results
if ((Test-Path $RebootRegKey1) -or (Test-Path $RebootRegKey2) -or (Test-Path $RebootRegKey3)) {
    $PendingReboot = $true
}

# Output Results in SolarWinds-Compatible Format
if ($PendingReboot -eq $true) {
    Write-Host "Message.RebootStatus: Server is pending reboot."
    Write-Host "Statistic.RebootStatus: 1"
    exit 2 # Critical
} else {
    Write-Host "Message.RebootStatus: Server is not pending reboot."
    Write-Host "Statistic.RebootStatus: 0"
    exit 0 # Up
}









# Minimal Reboot Pending Detection Script

# Define Registry Keys to Check
$RebootRegKeys = @(
    "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootPending",
    "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\WindowsUpdate\Auto Update\RebootRequired",
    "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootInProgress",
    "HKLM:\SYSTEM\CurrentControlSet\Control\Session Manager\PendingFileRenameOperations"
)

# Check for Pending Reboot
$PendingReboot = (
    ($RebootRegKeys | Where-Object { Test-Path $_ }) -or 
    (New-Object -ComObject Microsoft.Update.SystemInfo).RebootRequired
)

# Output Results in SolarWinds-Compatible Format
if ($PendingReboot) {
    Write-Host "Message.RebootStatus: Server is pending reboot"
    Write-Host "Statistic.RebootStatus: 1"
} else {
    Write-Host "Message.RebootStatus: Server is not pending reboot"
    Write-Host "Statistic.RebootStatus: 0"
}




# Streamlined Script to Check Pending Reboot



# Define Registry Keys to Check

$RebootRegKey1 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootPending"

$RebootRegKey2 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\WindowsUpdate\Auto Update\RebootRequired"

$RebootRegKey3 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootInProgress"



# Initialize Pending Reboot Flag

$PendingReboot = $false



# Check Registry Keys Individually and Combine Results

if ((Test-Path $RebootRegKey1) -or (Test-Path $RebootRegKey2) -or (Test-Path $RebootRegKey3)) {

    $PendingReboot = $true

}



# Output Results in SolarWinds-Compatible Format

if ($PendingReboot -eq $true) {

    Write-Host "Message.RebootStatus: Server is pending reboot."

    Write-Host "Statistic.RebootStatus: 1"

} else {

    Write-Host "Message.RebootStatus: Server is not pending reboot."

    Write-Host "Statistic.RebootStatus: 0"

}


##########################################################################################################################################################################################################################
# Streamlined Script to Check Pending Reboot

# Define Registry Keys to Check

$RebootRegKey1 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootPending"

$RebootRegKey2 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\WindowsUpdate\Auto Update\RebootRequired"

$RebootRegKey3 = "HKLM:\SOFTWARE\Microsoft\Windows\CurrentVersion\Component Based Servicing\RebootInProgress"



# Initialize Pending Reboot Flag

$PendingReboot = $false



# Check Registry Keys

if (Test-Path $RebootRegKey1 -or Test-Path $RebootRegKey2 -or Test-Path $RebootRegKey3) {

    $PendingReboot = $true

}



# Output Results in SolarWinds-Compatible Format

if ($PendingReboot -eq $true) {

    Write-Host "Message.RebootStatus: Server is pending reboot."

    Write-Host "Statistic.RebootStatus: 1"

} else {

    Write-Host "Message.RebootStatus: Server is not pending reboot."

    Write-Host "Statistic.RebootStatus: 0"

}





$PendingReboot = Get-WmiObject -Namespace "ROOT\CCM\ClientSDK" -Class CCM_ClientUtilities | Select-Object IsRebootPending
if ($PendingReboot.IsRebootPending -eq $true) {
    Write-Host "Message: Server is pending reboot."
    Write-Host "Statistic: 1"
} else {
    Write-Host "Message: Server is not pending reboot."
    Write-Host "Statistic: 0"
}








# Critical System Errors Alert for SolarWinds

# Get critical errors from the System event log in the last 24 hours
$criticalLogs = Get-EventLog -LogName System -EntryType Error, Critical |
    Where-Object { $_.TimeGenerated -gt (Get-Date).AddHours(-24) }

# Output results in SolarWinds-compatible format
if ($criticalLogs) {
    Write-Host "Message.CriticalErrors: Critical system errors detected in the last 24 hours"
    Write-Host "Statistic.ErrorCount: $($criticalLogs.Count)"
    exit 2 # Exit with Warning (2) status
} else {
    Write-Host "Message.CriticalErrors: No critical system errors detected in the last 24 hours"
    Write-Host "Statistic.ErrorCount: 0"
    exit 0 # Exit with Up (0) status
}




# Check for Windows Update Failure Events
$EventLogs = Get-WinEvent -LogName "Microsoft-Windows-WindowsUpdateClient/Operational" -FilterXPath "*[System[EventID=20]]" -MaxEvents 5

if ($EventLogs) {
    Write-Host "Message.UpdateFailure: Detected Windows Update failures."
    Write-Host "Statistic.UpdateFailure: 1" # Warning
    exit 1
} else {
    Write-Host "Message.UpdateFailure: No Windows Update failures detected."
    Write-Host "Statistic.UpdateFailure: 0" # Up
    exit 0
}





# Define the log and time range to search
$logName = "System"
$timeRange = (Get-Date).AddHours(-1) # Check for errors in the last hour

# Query the event log for Critical (Level 1) or Error (Level 2) events
$errors = Get-WinEvent -LogName $logName -FilterXPath "*[System[Level=1 or Level=2 and TimeCreated[timediff(@SystemTime) <= 3600000]]]" -MaxEvents 10

# Count the errors
$errorCount = $errors.Count

# Output for SolarWinds
Write-Host "Message: $errorCount critical or error events found in the $logName log within the last hour."
Write-Host "Statistic: $errorCount"

# Set exit codes based on the error count
if ($errorCount -eq 0) {
    exit 0 # Up
} elseif ($errorCount -le 5) {
    exit 1 # Warning
} else {
    exit 2 # Critical
}


Q&A
1. Why did I get this alert?
Key Points:

Alerts should provide actionable context to prevent confusion or unnecessary escalation.
Simply stating "something is down" without details is not helpful.
Improved Answer:

A good alert should include:

Server Name: Which system is impacted?
IP Address/DNS: Where is the system located, and how can it be accessed?
Responsible Team: Who is assigned to resolve this issue?
Specific Context: What exactly is the problem (e.g., CPU usage exceeded 90%)?
Thresholds: What are the thresholds that triggered the alert, and what is the current reading?
Link to KB or SOP: Include links to a relevant knowledge base article or standard operating procedure for guidance.
Why It’s Important:

Provides clarity and reduces resolution time.
Helps on-call engineers quickly assess the severity and next steps.
2. Why didn't I get that alert?
Key Points:

Sometimes alerts are intentionally suppressed or missed due to configurations or conditions.
Improved Answer:

Common reasons for not receiving alerts:

Change Windows: Alerts might be paused during scheduled maintenance.
Routing Differences: Alerts may be routed differently for day/night or holiday shifts.
Configuration Changes: Recent changes in system configurations might disable certain alerts temporarily.
Dynamic Resource Allocation: Alerts may not trigger if the system dynamically adjusts thresholds (e.g., autoscaling in cloud environments).
Alert Dependencies: Parent alerts suppress child alerts to avoid alert storms (e.g., server down suppresses application alerts).
Why It’s Important:

Understanding these nuances ensures teams know when and why alerts are expected or not, avoiding unnecessary escalations.
3. What is monitored on my system?
Key Points:

Knowing what’s monitored helps clarify coverage gaps and compliance.
Improved Answer:

Create comprehensive reports detailing:

System Names: Which servers, devices, or applications are under monitoring?
Monitored Metrics: Include metrics like CPU, memory, disk I/O, network latency, and custom KPIs.
Alert Thresholds: Define thresholds for each metric (e.g., CPU > 85% for 5 minutes).
Monitoring Tools: Specify tools and their configurations (e.g., SolarWinds, SNMP traps, custom scripts).
Exceptions: Note any exclusions (e.g., non-production systems).
Tools like SQL queries, Wireshark, or SolarWinds reports can help extract and visualize this data.

4. What will alert for my systems?
Key Points:

Understanding potential alerts helps teams prepare and prioritize responses.
Improved Answer:

Before deploying new systems or configurations, evaluate:

Potential Alerts: List all possible alerts (e.g., disk nearing capacity, service outages).
Alert Scenarios: Simulate failure scenarios to predict alert behavior.
Alert Workload: Assess if the frequency of alerts is manageable or needs fine-tuning.
Impact Assessment: Quantify the financial and operational impact of an alert (e.g., downtime costs).
Why It’s Important:

Prevents alert fatigue and ensures that all alerts are meaningful and actionable.
5. How can we standardize our monitoring approach?
Key Points:

A standardized monitoring approach improves communication and clarity.
Answer:

Establish a framework with the following components:

Baseline Metrics: Define universal metrics (CPU, memory, latency, etc.) that all systems must monitor.
Standard Templates: Use consistent alert templates for similar systems (e.g., web servers, database servers).
Ownership: Assign responsibility for each monitored system or service.
Centralized Documentation: Maintain a centralized repository for monitoring configurations, alert escalation procedures, and reports.
Why It’s Important:

Enables seamless collaboration across teams and minimizes ambiguity during incidents.
6. How do we prevent alert fatigue?
Key Points:

Too many alerts can overwhelm teams and cause important issues to be overlooked.
Answer:

Strategies to reduce alert fatigue:

Prioritize Alerts: Assign severity levels to alerts (e.g., Critical, Warning, Informational).
Aggregate Alerts: Group similar alerts (e.g., disk usage warnings across multiple servers).
Set Proper Thresholds: Avoid too-sensitive thresholds that cause false positives.
Automate Resolutions: For repetitive issues, automate responses (e.g., restart a service if it fails).
Why It’s Important:

Focuses team efforts on resolving critical incidents without distractions.
7. How do we ensure monitoring evolves with our infrastructure?
Key Points:

Monitoring configurations should adapt as the infrastructure scales or changes.
Answer:

Best practices to keep monitoring aligned:

Dynamic Discovery: Use tools like SolarWinds' auto-discovery to find new devices and services.
Regular Audits: Conduct quarterly reviews of monitored systems and alerts.
Version Tracking: Monitor changes in configurations or application versions that might introduce new metrics.
Training: Ensure teams are trained on updates to monitoring tools or processes.
Why It’s Important:

Keeps monitoring relevant and reduces blind spots in dynamic environments.
